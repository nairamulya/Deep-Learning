{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Wine data classification with EarlyStopping .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO4eOOUmB/3qE1ZLX/q/Epf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nairamulya/Deep-Learning/blob/master/Wine_data_classification_with_EarlyStopping_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VBWpk7pU1C7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bb8e6223-4bd5-41f6-9b4c-52b8e0b1c1c7"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "tf.random.set_random_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "wineData= load_wine()\n",
        "\n",
        "x=wineData.data\n",
        "y=wineData.target\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "sc.fit(x_train)\n",
        "\n",
        "x_train_std=sc.transform(x_train)\n",
        "\n",
        "x_test_std=sc.transform(x_test)\n",
        "\n",
        "model_DNN=keras.models.Sequential()\n",
        "\n",
        "model_DNN.add(keras.layers.Dense(units=15,activation='relu',input_shape=x_train.shape[1:]))\n",
        "model_DNN.add(keras.layers.BatchNormalization())\n",
        "model_DNN.add(keras.layers.Dense(units=12,activation='relu'))\n",
        "model_DNN.add(keras.layers.Dense(units=8,activation='relu'))\n",
        "model_DNN.add(keras.layers.Dense(units=4,activation='relu'))\n",
        "model_DNN.add(keras.layers.Dense(units=3,activation='softmax'))\n",
        "\n",
        "model_DNN.summary()\n",
        "\n",
        "model_DNN.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "cb_early_stopping=keras.callbacks.EarlyStopping(monitor='val_loss',patience=10,restore_best_weights=True)\n",
        "\n",
        "model_DNN.fit(x=x_train_std,y=y_train,validation_split=0.1,epochs=5000,batch_size=16,callbacks=[cb_early_stopping])\n",
        "\n",
        "test_loss,test_accuracy=model_DNN.evaluate(x=x_test_std,y=y_test)\n",
        "\n",
        "print(test_loss,test_accuracy)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 15)                210       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 15)                60        \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 12)                192       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 4)                 36        \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 15        \n",
            "=================================================================\n",
            "Total params: 617\n",
            "Trainable params: 587\n",
            "Non-trainable params: 30\n",
            "_________________________________________________________________\n",
            "Train on 127 samples, validate on 15 samples\n",
            "Epoch 1/5000\n",
            "127/127 [==============================] - 0s 3ms/sample - loss: 1.0151 - acc: 0.3701 - val_loss: 0.9658 - val_acc: 0.6000\n",
            "Epoch 2/5000\n",
            "127/127 [==============================] - 0s 277us/sample - loss: 0.9628 - acc: 0.4252 - val_loss: 0.8929 - val_acc: 0.6667\n",
            "Epoch 3/5000\n",
            "127/127 [==============================] - 0s 228us/sample - loss: 0.9247 - acc: 0.4252 - val_loss: 0.8220 - val_acc: 0.7333\n",
            "Epoch 4/5000\n",
            "127/127 [==============================] - 0s 205us/sample - loss: 0.8887 - acc: 0.5118 - val_loss: 0.7544 - val_acc: 0.8000\n",
            "Epoch 5/5000\n",
            "127/127 [==============================] - 0s 194us/sample - loss: 0.8620 - acc: 0.5591 - val_loss: 0.6967 - val_acc: 0.8000\n",
            "Epoch 6/5000\n",
            "127/127 [==============================] - 0s 222us/sample - loss: 0.8363 - acc: 0.5984 - val_loss: 0.6415 - val_acc: 0.8667\n",
            "Epoch 7/5000\n",
            "127/127 [==============================] - 0s 227us/sample - loss: 0.7784 - acc: 0.6535 - val_loss: 0.5743 - val_acc: 0.9333\n",
            "Epoch 8/5000\n",
            "127/127 [==============================] - 0s 192us/sample - loss: 0.7429 - acc: 0.6693 - val_loss: 0.5194 - val_acc: 0.9333\n",
            "Epoch 9/5000\n",
            "127/127 [==============================] - 0s 200us/sample - loss: 0.7333 - acc: 0.6772 - val_loss: 0.4818 - val_acc: 0.9333\n",
            "Epoch 10/5000\n",
            "127/127 [==============================] - 0s 189us/sample - loss: 0.7021 - acc: 0.7244 - val_loss: 0.4407 - val_acc: 0.9333\n",
            "Epoch 11/5000\n",
            "127/127 [==============================] - 0s 219us/sample - loss: 0.6737 - acc: 0.7402 - val_loss: 0.4074 - val_acc: 0.9333\n",
            "Epoch 12/5000\n",
            "127/127 [==============================] - 0s 282us/sample - loss: 0.6181 - acc: 0.7638 - val_loss: 0.3817 - val_acc: 0.9333\n",
            "Epoch 13/5000\n",
            "127/127 [==============================] - 0s 183us/sample - loss: 0.5935 - acc: 0.7638 - val_loss: 0.3544 - val_acc: 0.8667\n",
            "Epoch 14/5000\n",
            "127/127 [==============================] - 0s 184us/sample - loss: 0.5541 - acc: 0.7480 - val_loss: 0.3308 - val_acc: 0.8667\n",
            "Epoch 15/5000\n",
            "127/127 [==============================] - 0s 197us/sample - loss: 0.5276 - acc: 0.7795 - val_loss: 0.3054 - val_acc: 0.8667\n",
            "Epoch 16/5000\n",
            "127/127 [==============================] - 0s 201us/sample - loss: 0.5418 - acc: 0.7638 - val_loss: 0.2852 - val_acc: 0.8667\n",
            "Epoch 17/5000\n",
            "127/127 [==============================] - 0s 201us/sample - loss: 0.5081 - acc: 0.8110 - val_loss: 0.2694 - val_acc: 0.8667\n",
            "Epoch 18/5000\n",
            "127/127 [==============================] - 0s 187us/sample - loss: 0.4681 - acc: 0.8268 - val_loss: 0.2525 - val_acc: 0.9333\n",
            "Epoch 19/5000\n",
            "127/127 [==============================] - 0s 201us/sample - loss: 0.4874 - acc: 0.8425 - val_loss: 0.2334 - val_acc: 1.0000\n",
            "Epoch 20/5000\n",
            "127/127 [==============================] - 0s 203us/sample - loss: 0.4554 - acc: 0.8425 - val_loss: 0.2169 - val_acc: 1.0000\n",
            "Epoch 21/5000\n",
            "127/127 [==============================] - 0s 216us/sample - loss: 0.4269 - acc: 0.8819 - val_loss: 0.2061 - val_acc: 1.0000\n",
            "Epoch 22/5000\n",
            "127/127 [==============================] - 0s 198us/sample - loss: 0.4441 - acc: 0.8819 - val_loss: 0.1982 - val_acc: 1.0000\n",
            "Epoch 23/5000\n",
            "127/127 [==============================] - 0s 177us/sample - loss: 0.4074 - acc: 0.9134 - val_loss: 0.1855 - val_acc: 1.0000\n",
            "Epoch 24/5000\n",
            "127/127 [==============================] - 0s 213us/sample - loss: 0.3754 - acc: 0.9213 - val_loss: 0.1785 - val_acc: 1.0000\n",
            "Epoch 25/5000\n",
            "127/127 [==============================] - 0s 193us/sample - loss: 0.4003 - acc: 0.9055 - val_loss: 0.1717 - val_acc: 1.0000\n",
            "Epoch 26/5000\n",
            "127/127 [==============================] - 0s 194us/sample - loss: 0.3419 - acc: 0.9685 - val_loss: 0.1653 - val_acc: 1.0000\n",
            "Epoch 27/5000\n",
            "127/127 [==============================] - 0s 195us/sample - loss: 0.3439 - acc: 0.9606 - val_loss: 0.1594 - val_acc: 1.0000\n",
            "Epoch 28/5000\n",
            "127/127 [==============================] - 0s 202us/sample - loss: 0.3027 - acc: 0.9685 - val_loss: 0.1518 - val_acc: 1.0000\n",
            "Epoch 29/5000\n",
            "127/127 [==============================] - 0s 201us/sample - loss: 0.3154 - acc: 0.9528 - val_loss: 0.1437 - val_acc: 1.0000\n",
            "Epoch 30/5000\n",
            "127/127 [==============================] - 0s 221us/sample - loss: 0.2673 - acc: 0.9685 - val_loss: 0.1327 - val_acc: 1.0000\n",
            "Epoch 31/5000\n",
            "127/127 [==============================] - 0s 216us/sample - loss: 0.2253 - acc: 0.9921 - val_loss: 0.1171 - val_acc: 1.0000\n",
            "Epoch 32/5000\n",
            "127/127 [==============================] - 0s 198us/sample - loss: 0.2343 - acc: 0.9843 - val_loss: 0.1043 - val_acc: 1.0000\n",
            "Epoch 33/5000\n",
            "127/127 [==============================] - 0s 212us/sample - loss: 0.1857 - acc: 1.0000 - val_loss: 0.0925 - val_acc: 1.0000\n",
            "Epoch 34/5000\n",
            "127/127 [==============================] - 0s 201us/sample - loss: 0.1613 - acc: 0.9921 - val_loss: 0.0826 - val_acc: 1.0000\n",
            "Epoch 35/5000\n",
            "127/127 [==============================] - 0s 232us/sample - loss: 0.1817 - acc: 0.9606 - val_loss: 0.0870 - val_acc: 1.0000\n",
            "Epoch 36/5000\n",
            "127/127 [==============================] - 0s 208us/sample - loss: 0.1494 - acc: 0.9764 - val_loss: 0.0885 - val_acc: 1.0000\n",
            "Epoch 37/5000\n",
            "127/127 [==============================] - 0s 214us/sample - loss: 0.1100 - acc: 1.0000 - val_loss: 0.0818 - val_acc: 1.0000\n",
            "Epoch 38/5000\n",
            "127/127 [==============================] - 0s 180us/sample - loss: 0.1058 - acc: 0.9843 - val_loss: 0.0771 - val_acc: 1.0000\n",
            "Epoch 39/5000\n",
            "127/127 [==============================] - 0s 192us/sample - loss: 0.0764 - acc: 1.0000 - val_loss: 0.0776 - val_acc: 1.0000\n",
            "Epoch 40/5000\n",
            "127/127 [==============================] - 0s 181us/sample - loss: 0.0964 - acc: 0.9921 - val_loss: 0.0728 - val_acc: 1.0000\n",
            "Epoch 41/5000\n",
            "127/127 [==============================] - 0s 270us/sample - loss: 0.1288 - acc: 0.9764 - val_loss: 0.0581 - val_acc: 1.0000\n",
            "Epoch 42/5000\n",
            "127/127 [==============================] - 0s 274us/sample - loss: 0.0695 - acc: 1.0000 - val_loss: 0.0542 - val_acc: 1.0000\n",
            "Epoch 43/5000\n",
            "127/127 [==============================] - 0s 223us/sample - loss: 0.0814 - acc: 0.9843 - val_loss: 0.0464 - val_acc: 1.0000\n",
            "Epoch 44/5000\n",
            "127/127 [==============================] - 0s 216us/sample - loss: 0.0717 - acc: 0.9843 - val_loss: 0.0355 - val_acc: 1.0000\n",
            "Epoch 45/5000\n",
            "127/127 [==============================] - 0s 216us/sample - loss: 0.0668 - acc: 0.9843 - val_loss: 0.0362 - val_acc: 1.0000\n",
            "Epoch 46/5000\n",
            "127/127 [==============================] - 0s 222us/sample - loss: 0.0787 - acc: 0.9843 - val_loss: 0.0334 - val_acc: 1.0000\n",
            "Epoch 47/5000\n",
            "127/127 [==============================] - 0s 219us/sample - loss: 0.0523 - acc: 0.9921 - val_loss: 0.0365 - val_acc: 1.0000\n",
            "Epoch 48/5000\n",
            "127/127 [==============================] - 0s 251us/sample - loss: 0.0472 - acc: 0.9921 - val_loss: 0.0554 - val_acc: 1.0000\n",
            "Epoch 49/5000\n",
            "127/127 [==============================] - 0s 242us/sample - loss: 0.0339 - acc: 0.9921 - val_loss: 0.0761 - val_acc: 0.9333\n",
            "Epoch 50/5000\n",
            "127/127 [==============================] - 0s 231us/sample - loss: 0.0781 - acc: 0.9764 - val_loss: 0.0938 - val_acc: 0.9333\n",
            "Epoch 51/5000\n",
            "127/127 [==============================] - 0s 211us/sample - loss: 0.0453 - acc: 0.9921 - val_loss: 0.0891 - val_acc: 0.9333\n",
            "Epoch 52/5000\n",
            "127/127 [==============================] - 0s 202us/sample - loss: 0.0410 - acc: 0.9921 - val_loss: 0.0630 - val_acc: 1.0000\n",
            "Epoch 53/5000\n",
            "127/127 [==============================] - 0s 187us/sample - loss: 0.0302 - acc: 1.0000 - val_loss: 0.0510 - val_acc: 1.0000\n",
            "Epoch 54/5000\n",
            "127/127 [==============================] - 0s 201us/sample - loss: 0.0412 - acc: 1.0000 - val_loss: 0.0484 - val_acc: 1.0000\n",
            "Epoch 55/5000\n",
            "127/127 [==============================] - 0s 216us/sample - loss: 0.0400 - acc: 0.9921 - val_loss: 0.0712 - val_acc: 0.9333\n",
            "Epoch 56/5000\n",
            "127/127 [==============================] - 0s 800us/sample - loss: 0.0294 - acc: 0.9921 - val_loss: 0.0928 - val_acc: 0.9333\n",
            "36/36 [==============================] - 0s 145us/sample - loss: 0.0394 - acc: 1.0000\n",
            "0.039430859602159925 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "172CJCDMWiLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}